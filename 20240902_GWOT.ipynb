{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'raw_data/kana_colourpreferencequalia-master/data'\n",
    "\n",
    "# Specify the data column to focus on throughout by default\n",
    "data_column = 'responseTime' # 'response' or 'responseTime'\n",
    "\n",
    "# Specify which type of responses to filter for\n",
    "response_type = 'preference' # 'similarity' or 'preference'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "import sys\n",
    "sys.path.append('/Users/kana/Library/Mobile Documents/com~apple~CloudDocs/Codes/GWOT_colorprefrencequalia')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import csv\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.manifold import MDS\n",
    "import seaborn as sns\n",
    "import ot\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import math\n",
    "\n",
    "# Our own utility functions\n",
    "import utilityFunctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define variables/functions (used across the code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define unique colors\n",
    "# TODO - remove after confirming that it is no longer needed (replaced by function)\n",
    "unique_colours = np.array(['#d2b700', '#db8b08', '#c7512c', '#c13547', '#a03663', '#753a7a', '#4b488e', '#005692', '#006a8b', '#007b75', '#008a52', '#9aa400'])\n",
    "colour_index = {colour: idx for idx, colour in enumerate(unique_colours)}\n",
    "matrix_size = len(unique_colours)\n",
    "\n",
    "# Provides dictionary of colours, with an assigned id for each colour\n",
    "# OUTPUTS:\n",
    "#   colour_index: dictionary, {colour_string : colour_id}\n",
    "def getUniqueColours():\n",
    "    unique_colours = np.array(['#d2b700', '#db8b08', '#c7512c', '#c13547', '#a03663', '#753a7a', '#4b488e', '#005692', '#006a8b', '#007b75', '#008a52', '#9aa400'])\n",
    "    colour_index = {colour: idx for idx, colour in enumerate(unique_colours)}\n",
    "    return colour_index\n",
    "\n",
    "### configuration\n",
    "n_eps = 15 # number of epsilon values tried\n",
    "eps_range = [0.04, 5] # the range of epsilon searched\n",
    "epsilons = np.logspace(np.log10(eps_range[0]), np.log10(eps_range[1]), n_eps) # epsilon values\n",
    "\n",
    "# Set default font size\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function(s) for loading and formatting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for getting data\n",
    "\n",
    "# Extract data from datafiles in provided directory\n",
    "#   Data is extracted in the colour x colour matrix form\n",
    "# INPUTS:\n",
    "#   data_dir: string, directory holding csv data files\n",
    "#   target_data: string, target column name in data files which has the data you want to get\n",
    "#   response_type: string, select data for 'similarity' or 'preference'\n",
    "# OUTPUTS:\n",
    "#   pMatrices:\n",
    "#   pIds:\n",
    "#   pFiles:\n",
    "# TODO add parameter which allows for filtering of data based on specified column-value pairs\n",
    "def getDataColourMatrix(data_dir, target_data, response_type):\n",
    "\n",
    "    pFiles = [] # stores source datafile for each participant, pFiles[pID] gives the file for participant pID\n",
    "    pMatrices = [] # stores data matrix for each participant\n",
    "\n",
    "    pCounter = 0 \n",
    "    for filename in utilityFunctions.sort_files_in_directory(data_dir):# sorted(os.listdir(data_dir), reverse=False):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            filepath = os.path.join('raw_data/kana_colourpreferencequalia-master/data', filename)\n",
    "\n",
    "            # This is another participant\n",
    "            pFiles.append(filename)\n",
    "            pCounter = pCounter + 1\n",
    "            \n",
    "            # Load the CSV file\n",
    "            df = pd.read_csv(filepath)\n",
    "\n",
    "            # Omit practice trials\n",
    "            df = df[df['practice_trial'] != 1]\n",
    "\n",
    "            # Filter for rows where 'response_type' is 'similarity' or 'preference'\n",
    "            df_similarity = df[df['response_type'] == response_type]\n",
    "\n",
    "            # Extract columns\n",
    "            # colour1 is the left colour, colour2 is the right colour\n",
    "            colour1 = df_similarity['colour1']\n",
    "            colour2 = df_similarity['colour2']\n",
    "            target_preference = df_similarity[target_data]\n",
    "\n",
    "            \"\"\"\n",
    "            # Create and fill the matrix\n",
    "            # NOTE here, double pass trials will overwrite the first trials (is this what we want?)\n",
    "            colour_index = getUniqueColours()\n",
    "            matrix_size = len(colour_index)\n",
    "            matrix = np.zeros((matrix_size, matrix_size))\n",
    "            for c1, c2, tp in zip(colour1, colour2, target_preference):\n",
    "                I = colour_index[c1]\n",
    "                j = colour_index[c2]\n",
    "                matrix[j, I] = tp\n",
    "            \"\"\"\n",
    "\n",
    "            # Create and fill the matrix\n",
    "            # For double pass trials, take the average between the first and second pass\n",
    "            colour_index = getUniqueColours()\n",
    "            matrix_size = len(colour_index)\n",
    "            matrix = np.zeros((matrix_size, matrix_size))\n",
    "            matrix_entryCount = np.zeros((matrix_size, matrix_size))\n",
    "            for c1, c2, tp in zip(colour1, colour2, target_preference):\n",
    "                i = colour_index[c1] # rows correspond to left colour\n",
    "                j = colour_index[c2] # cols correspond to right colour\n",
    "                matrix[i, j] = matrix[i, j] + tp\n",
    "                matrix_entryCount[i, j] = matrix_entryCount[i, j] + 1\n",
    "            matrix = np.divide(matrix, matrix_entryCount)\n",
    "\n",
    "            # Store the matrix\n",
    "            pMatrices.append(matrix)\n",
    "\n",
    "    pIds = range(0, pCounter)\n",
    "\n",
    "    return pMatrices, pIds, pFiles\n",
    "\n",
    "# Compute double pass correlations from datafiles in provided directory\n",
    "# INPUTS:\n",
    "#   data_dir: string, directory holding csv data files\n",
    "#   response_type: string, specify to compute correlations for\n",
    "#    'similarity' or 'preference' ratings\n",
    "# OUTPUTS:\n",
    "#   pCorrs: vector of double-pass correlations for each participant\n",
    "def getDoublePassCorrelations(data_dir, response_type):\n",
    "    \n",
    "    pCorrs = []\n",
    "\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            filepath = os.path.join(data_dir, filename)\n",
    "            \n",
    "            df = pd.read_csv(filepath, usecols=['response_type', 'response', 'colour1', 'colour2', 'trials.thisIndex', 'practice_trial'])\n",
    "\n",
    "            # Omit practice trials\n",
    "            df = df[df['practice_trial'] != 1]\n",
    "\n",
    "            df_similarity = df[df['response_type'] == response_type]\n",
    "\n",
    "            # Group by 'trials.thisIndex'\n",
    "            grouped = df_similarity.groupby('trials.thisIndex')['response'].apply(list).reset_index()\n",
    "\n",
    "            # Filter for pairs with exactly two trials\n",
    "            repeated_pairs = grouped[grouped['response'].apply(len) == 2]\n",
    "\n",
    "            # Check if there are any repeated pairs\n",
    "            if len(repeated_pairs) > 0:\n",
    "                # Flatten the responses for repeated pairs\n",
    "                responses_trial1 = np.array(repeated_pairs['response'].apply(lambda x: x[0]).tolist())\n",
    "                responses_trial2 = np.array(repeated_pairs['response'].apply(lambda x: x[1]).tolist())\n",
    "\n",
    "                # Calculate overall correlation for repeated color pairs\n",
    "                overall_correlation = pearsonr(responses_trial1, responses_trial2)[0]\n",
    "\n",
    "                pCorrs.append(overall_correlation)\n",
    "\n",
    "                #print(f\"Overall {response_type} Pearson Correlation for {filename}: {overall_correlation}\")\n",
    "            else:\n",
    "                print(f\"No repeated pairs found in {filename}\")\n",
    "\n",
    "    return pCorrs\n",
    "\n",
    "# Display multiple matrices as a subplot\n",
    "#\n",
    "# INPUTS:\n",
    "#   vmin_val: number, minimum of colour scale\n",
    "#   vmin_val: number, maximum of colour scale\n",
    "#   matrices: list, list of 2D numpy matrices\n",
    "#   rows: integer, how many subplot rows\n",
    "#   cols: integer, how many subplot columns\n",
    "#   titles: list, list of title strings for each subplot\n",
    "#   cbar_label: string, title for colour bars\n",
    "#   color_labels: dictionary, dictionary of colours and their ids (x/y axis position), {colour:id}\n",
    "# OUTPUTS:\n",
    "#   Returns nothing, just plots\n",
    "def show_heatmaps(vmin_val, vmax_val, matrices, rows, cols, titles, cbar_label=None, color_labels=None):\n",
    "    num_plots = len(matrices)\n",
    "    grid_size = math.ceil(math.sqrt(num_plots))  # Determine the grid size\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(16, 9)) #figsize=(5 * grid_size, 5 * grid_size))\n",
    "\n",
    "    textsize = (14*6) * (1/cols) # scale font size based on number of panels\n",
    "\n",
    "   # Flatten the axes array if it is 2D\n",
    "    if isinstance(axs, np.ndarray):\n",
    "        axs = axs.ravel()\n",
    "    else:\n",
    "        axs = [axs]\n",
    "\n",
    "    for i, (matrix, title) in enumerate(zip(matrices, titles)):\n",
    "        ax = axs[i]\n",
    "        \n",
    "        im = ax.imshow(matrix, aspect='auto', vmin=vmin_val, vmax=vmax_val)\n",
    "        ax.set_title(title, fontsize=textsize)\n",
    "\n",
    "        # Set axis labels\n",
    "        ax.set_xlabel(\"Right\")  # Label for x-axis\n",
    "        ax.set_ylabel(\"Left\")   # Label for y-axis\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "        # Shift the x and y labels to avoid overlap with colored labels\n",
    "        ax.xaxis.set_label_coords(0.55, 0.025)  # Adjust xlabel position to account for colour labels\n",
    "        ax.yaxis.set_label_coords(0.075, 0.55)  # Adjust ylabel position to account for colour labels\n",
    "\n",
    "        ax.axis('square')\n",
    "\n",
    "        if color_labels is not None:\n",
    "            #ax.axis('off')\n",
    "            for idx, color in enumerate(color_labels):\n",
    "                utilityFunctions.add_colored_label(ax, -1.5, idx - 0.5, color, width=0.8)\n",
    "                utilityFunctions.add_colored_label(ax, idx - 0.5, matrix.shape[1] - 0.2, color, height=0.8)\n",
    "\n",
    "            ax.set_aspect('equal')\n",
    "            ax.set_xlim(-3.0, matrix.shape[1])\n",
    "            ax.set_ylim(-1, len(color_labels) + 1.4)\n",
    "            ax.invert_yaxis()\n",
    "\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_visible(False)\n",
    "        \n",
    "        # Add colorbar\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        cbar = fig.colorbar(im, cax=cax)\n",
    "        cbar.set_label(cbar_label, fontsize=textsize)\n",
    "        cbar.ax.tick_params(labelsize=textsize)\n",
    "\n",
    "        # Adjust colorbar height to match the axis height dynamically\n",
    "        ax_pos = ax.get_position()  # Get the subplot's position\n",
    "        cax_pos = cax.get_position()  # Get the colorbar's position\n",
    "        cax.set_position([cax_pos.x0, ax_pos.y0, cax_pos.width, ax_pos.height])  # Match height\n",
    "\n",
    "        \"\"\"\n",
    "        # Adjust the height of the color bar\n",
    "        position = cax.get_position()\n",
    "        new_position = [position.x0, position.y0 + 0.1, position.width, position.height * 0.8]\n",
    "        cax.set_position(new_position)\n",
    "        \"\"\"\n",
    "    # Hide unused axes\n",
    "    for ax in axs[num_plots:]:\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create nested dictionary \"data\" holding response matrices for each participant\n",
    "# data['similarity' | 'preference']['response' | 'responseTime']\n",
    "\n",
    "dataMatrices = dict()\n",
    "dataParticipants = dict()\n",
    "dataFiles = dict()\n",
    "dataMatricesMean = dict() # Mean across participants\n",
    "\n",
    "response_types = ['similarity', 'preference']\n",
    "data_columns = ['response', 'responseTime']\n",
    "\n",
    "for r in response_types:\n",
    "    dataMatrices[r] = dict()\n",
    "    dataParticipants[r] = dict()\n",
    "    dataFiles[r] = dict()\n",
    "    dataMatricesMean[r] = dict()\n",
    "    for d in data_columns:\n",
    "        pMatrices, pIds, pFiles = getDataColourMatrix(data_dir, d, r)\n",
    "        dataMatrices[r][d] = pMatrices\n",
    "        dataParticipants[r][d] = pIds\n",
    "        dataFiles[r][d] = pFiles\n",
    "\n",
    "        # Average across participants\n",
    "        pMatrices_cat = np.stack(pMatrices, axis=2)\n",
    "        dataMatricesMean[r][d] = np.mean(pMatrices_cat, axis=2)\n",
    "\n",
    "\n",
    "## Compute double pass correlations for each participant and response type\n",
    "\n",
    "pCorrs = dict()\n",
    "for r in response_types:\n",
    "    pCorrs[r] = getDoublePassCorrelations(data_dir, r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show response matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "# Matrices, pIds, pFiles = getDataColourMatrix(data_dir, data_column, response_type)\n",
    "\n",
    "response_type = 'preference' # 'similarity' or 'preference'\n",
    "data_column = 'response' # 'response' or 'responseTime'\n",
    "\n",
    "pMatrices = dataMatrices[response_type][data_column]\n",
    "pIds = dataParticipants[response_type][data_column]\n",
    "pFiles = dataFiles[response_type][data_column]\n",
    "\n",
    "if data_column == 'responseTime':\n",
    "    cLabel = 'response time (s)'\n",
    "else:\n",
    "    cLabel = response_type\n",
    "\n",
    "# Show matrices\n",
    "if data_column == 'response':\n",
    "    # Range of raw response values\n",
    "    colour_min = 0\n",
    "    colour_max = 7\n",
    "elif data_column == 'responseTime':\n",
    "    # Range of response time values (0 is min)\n",
    "    colour_min = 0\n",
    "    colour_max = 5\n",
    "\n",
    "show_heatmaps(colour_min, colour_max, pMatrices, 4, 6, titles=[\"subject\" + str(p) for p in pIds], cbar_label= cLabel, color_labels=unique_colours)\n",
    "\n",
    "for f in range(0, len(pFiles)):\n",
    "    print(\"subject\" + str(f) + ' ' + pFiles[f])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaged response matrix\n",
    "\n",
    "show_heatmaps(colour_min, colour_max, [dataMatricesMean['similarity'][data_column], dataMatricesMean['preference'][data_column]], 1, 2, titles=[\"mean \" + r for r in response_types], cbar_label='rating', color_labels=unique_colours)\n",
    "\n",
    "\n",
    "print(dataMatricesMean['similarity'][data_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of responses per participant\n",
    "\n",
    "num_plots = len(pMatrices)\n",
    "grid_size = math.ceil(math.sqrt(num_plots))  # Determine the grid size\n",
    "fig, axs = plt.subplots(4, 6, figsize=(16, 9))#, figsize=(5 * grid_size, 5 * grid_size))\n",
    "text_fontsize = 14\n",
    "\n",
    "# Flatten the axes array if it is 2D\n",
    "if isinstance(axs, np.ndarray):\n",
    "    axs = axs.ravel()\n",
    "else:\n",
    "    axs = [axs]\n",
    "\n",
    "if data_column == 'responseTime':\n",
    "    xlabel = 'responseTime (ms)'\n",
    "else:\n",
    "    xlabel = data_column\n",
    "\n",
    "for p in range(0, len(pMatrices)):\n",
    "    ax = axs[p]\n",
    "\n",
    "    ax.hist(pMatrices[p].flatten(), bins=50, color='blue')\n",
    "    ax.set_xlabel(xlabel, fontsize=text_fontsize)\n",
    "    ax.set_ylabel('count', fontsize=text_fontsize)\n",
    "    ax.set_title('subject' + str(p), fontsize=text_fontsize)\n",
    "\n",
    "    ax.tick_params(axis='both', labelsize=text_fontsize)\n",
    "\n",
    "# Hide unused axes\n",
    "for ax in axs[num_plots:]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mean response of each participant against variance\n",
    "\n",
    "response_type = 'preference' # 'similarity' or 'preference'\n",
    "data_column = 'responseTime' # 'response' or 'responseTime'\n",
    "\n",
    "pMatrices = dataMatrices[response_type][data_column]\n",
    "\n",
    "means = np.empty(len(pMatrices))\n",
    "vars = np.empty(len(pMatrices))\n",
    "\n",
    "for p in range(0, len(pMatrices)):\n",
    "    pMat = pMatrices[p].flatten()\n",
    "\n",
    "    # Take log of values if response time\n",
    "    if data_column == 'responseTime':\n",
    "        pMat = np.log(pMat)\n",
    "\n",
    "    means[p] = np.mean(pMat)\n",
    "    vars[p] = np.var(pMat)\n",
    "\n",
    "plt.scatter(means, vars)\n",
    "plt.xlabel(f'mean of {response_type} {data_column}s')\n",
    "plt.ylabel(f'variance of {response_type} {data_column}s')\n",
    "plt.title('mean vs variance of responses')\n",
    "\n",
    "#f\"Overall {response_type} Pearson Correlation for {filename}: {overall_correlation}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.jointplot(x=means, y=vars, kind='scatter', marginal_kws=dict(bins=20, fill=True), color='blue')\n",
    "plt.xlabel(f'mean of {response_type} {data_column}s')\n",
    "plt.ylabel(f'variance of {response_type} {data_column}s')\n",
    "\n",
    "plt.suptitle('mean vs variance of responses', fontsize=16, y=1.05)\n",
    "\n",
    "plt.axis('square')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double pass correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of double pass correlations across participants\n",
    "\n",
    "# response_type = 'similarity' # 'similarity' or 'preference'\n",
    "\n",
    "plt.hist(pCorrs[response_type], color='blue')\n",
    "plt.xlabel(\"r\")\n",
    "plt.ylabel(\"N\")\n",
    "plt.title('double pass - similarity')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot doublePass(preference) against doublePass(similarity)\n",
    "\n",
    "\n",
    "plt.scatter(pCorrs['similarity'], pCorrs['preference'])\n",
    "plt.xlabel('r(sim)')\n",
    "plt.ylabel('r(pref)')\n",
    "plt.title('double pass - similarity vs preference')\n",
    "\n",
    "#plt.axis('tight')\n",
    "plt.xlim(-0.1, 1)\n",
    "plt.ylim(-0.1, 1)\n",
    "\n",
    "plt.plot([-1, 1], [-1, 1], 'k', linewidth=1)  # Black dashed line"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
